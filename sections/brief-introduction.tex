Formal definition of a machine learning algorithm is given by \cite{Mitchell:1997:ML:541177}: "A computer program is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$ if its performance at tasks in $T$, as measured by $P$, improves with experience $E$." 
From such a definition, it is obvious that complete introduction to machine learning is too broad topic and hence in this thesis background on \textit{image classification} is only provided. That should be enough for a non-expert to be able to read and to understand this whole thesis.

As explained in REFERENCE-SECTION-1.1, an image classification is a task of assigning a \textit{label} or a \textit{class} to an image. If an input is $n$-dimensional vector and there are $k$ classes, then the learning algorithm is usually asked to produce a function $f: \mathbb{R}^n \rightarrow \{1, ... , k\}$. One other variant of a classification task would be to produce a function $f$ which outputs a probability distribution over classes, i.e. how likely each class is. In such a scenario, next step usually is to assign a label according to the most likely class, but it must not be the case. A model that is used for classification task is called a \textit{classifier}.

After defining a task, it is important to know how to measure the performance of a model. Depending on the domain of a system, this measure can vary. However, for a classification task, the \textit{accuracy} of the model is measured. It is the fraction of correct predictions of the model. For example, if the model was correct for 8 out of 10 samples, the accuracy of that model (on those 10 samples) is $0.8$ or $80\%$. An equivalent information can be obtained by measuring the \textit{error rate} which is defined as the fraction of incorrect predictions of the model. 

Usually we are interested how good the model is on previously unseen data, because that way we can see how good will it work in the real world application. Therefore, we measure its performance on a set of data which is not used during training. Such a set of data is called \textit{test set}. A test set is subset of an entire \textit{dataset}.

A dataset is a collection of samples. One of the oldest datasets is Iris flower dataset \cite{iris-dataset}. The dataset consists of 50 samples from each of three species of Iris. For each sample, four measures are taken: the length and the width of the sepals and petals, in centimeter. A measurable property of a sample is called a \textit{feature}. Hence, Iris dataset has 3 classes, 150 samples and each sample has 4 features. A classifier for that dataset could be modelled as a function $f: \mathbb{R}^4 \rightarrow \{0, 1, 2\}$.
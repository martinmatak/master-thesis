In Section \ref{sec:blackbox-attacks} I made the observation that the transfer based approach expects more memory than is available to me. In the same section I also present poor results of the transfer-based approach without Jacobian Augmentation. In this chapter I introduce an adaptation of the transfer-based approach.

\section{Motivation}
High memory expectation, poor results without Jacobian augmentation, and higher transferability of adversarial samples crafted in misclassification attacks than transferability of adversarial samples crafted in targeted misclassification attacks \cite{ensemble-attack} motivated me to modify the transfer-based approach.

In the modified approach the substitute network has a lower number of classes than the black-box model is expected to have and the goal of an attack against the substitute network is not a targeted misclassification, but only a misclassification. I call the modified approach \textit{the semi-targeted approach}.

In the semi targeted approach a substitute neural network has only several classes and every class represents a certain age interval. If a misclassification occurs in such a scenario, that means that the classifier is tricked at least for the amount of years corresponding to the age interval. In this thesis all age intervals have the same length, but in general this is not necessary.

Let me provide an example. Assume a substitute network with only three classes that represent age intervals 0-33, 34-66 and 67-99 years. Now if a person who is 50 years old gets misclassified, that means the person got classified as 0-33 years old or as 67-99 years old. In either case, the mistake is greater than getting classified as 51 or 49 years old as it would be the case when the substitute network would have 100 classes. Finally, if that adversarial sample transfers to targeted black-box network, then the black-box model will also have a large error.

\section{Evaluation}
In Section \ref{sec:blackbox-attacks} it is shown that FGSM has better results and it is used in this approach. To make the semi-targeted approach and the transfer based approach comparable, hyperparameters of the FGSM attack as well as training and test samples are completely the same as in Section \ref{sec:blackbox-attacks}. 

Jacobian Augmentation is performed for three iterations before executing an attack as described in Section \ref{sec:transfer-based} that describes the transfer based approach. I also tried with four iterations for Jacobian Augmentation, but the system crashed. 

In my experiments, the substitute network recognizes four classes: 0-25, 26-50, 51-75, and 76-99 years old. The number of epochs used for training the substitute network is set to 40.

Since the substitute network is trained on four classes, accuracy is used as a measure for evaluation of the network. For the targeted black-box neural network, MAE is used as a measure. Results are presented in Tables
\ref{table:semi-targeted-resnet50-sgd-fgsm},
\ref{table:semi-targeted-resnet50-adam-fgsm}, 
\ref{table:semi-targeted-inception-sgd-fgsm}, and
\ref{table:semi-targeted-inception-adam-fgsm}.


\begin{table}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
 & \multicolumn{2}{c|}{clean samples} & \multicolumn{6}{c|}{adversarial samples} \\ \hline
blackbox model id & blackbox MAE & substitute accuracy & blackbox MAE & substitute accuracy & avg L2 & std dev L2 & min L2 & max L2 \\ \hline
1 &  6.08 & 0.52 & 6.16 & 0.31 & 1891.38 & 56.60 &  1668.86 & 1939.89 \\ \hline
2 & 6.99 & 0.56 & 8.40 & 0.28 & 1891.56 &  57.99 & 1577.01 & 1939.89 \\ \hline
3 & 5.29 & 0.41 & 5.39  & 0.32 & 1890.05 & 61.06 & 1540.43 & 1939.89  \\ \hline
4 & 3.75 & 0.54 & 3.92 & 0.30 & 1892.46  & 55.13 & 1666.18 & 1939.89  \\ \hline
\end{tabular}%
}
\caption{Substitute network: ResNet50 architecture with SGD optimizer; Attack: FGSM}
\label{table:semi-targeted-resnet50-sgd-fgsm}
\end{table}


\begin{table}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
 & \multicolumn{2}{c|}{clean samples} & \multicolumn{6}{c|}{adversarial samples} \\ \hline
blackbox model id & blackbox MAE & substitute accuracy & blackbox MAE & substitute accuracy & avg L2 & std dev L2 & min L2 & max L2 \\ \hline
1 &  6.08 & 0.60 & 6.17 & 0.60  & 1856.08 & 271.20 &  0.00 & 1939.89 \\ \hline
2 & 6.99 & 0.60 & 8.41 & 0.60 & 1871.71 & 153.83 & 0.00 & 1939.89 \\ \hline
3 & 5.29 & 0.59 & 5.50  & 0.60 & 1213.41 & 911.17 & 0.00 & 1939.89  \\ \hline
4 & 3.75 & 0.60 & 3.75 & 0.60 & 0.00  & 0.00 & 0.00  & 0.00  \\ \hline
\end{tabular}%
}
\caption{Substitute network: ResNet50 architecture with Adam optimizer; Attack: FGSM}
\label{table:semi-targeted-resnet50-adam-fgsm}
\end{table}

\begin{table}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
 & \multicolumn{2}{c|}{clean samples} & \multicolumn{6}{c|}{adversarial samples} \\ \hline
blackbox model id & blackbox MAE & substitute accuracy & blackbox MAE & substitute accuracy & avg L2 & std dev L2 & min L2 & max L2 \\ \hline
1 &  6.08 & 0.67 & 6.00 & 0.37  & 2525.36 & 76.90 &  2102.57 & 2589.41 \\ \hline
2 & 6.99 & 0.68 & 9.25 & 0.30 & 2525.20 & 76.96 & 2103.83 & 2589.41 \\ \hline
3 & 5.29 & 0.69 & 7.75  & 0.35 & 2525.43 & 76.61 & 2108.77 & 2589.41  \\ \hline
4 & 3.75 & 0.74 & 4.83 & 0.34 & 2525.48  & 76.57 & 2105.55  & 2589.41  \\ \hline
\end{tabular}%
}
\caption{Substitute network: InceptionResNetV2 architecture with SGD optimizer; Attack: FGSM}
\label{table:semi-targeted-inception-sgd-fgsm}
\end{table}

\begin{table}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
 & \multicolumn{2}{c|}{clean samples} & \multicolumn{6}{c|}{adversarial samples} \\ \hline
blackbox model id & blackbox MAE & substitute accuracy & blackbox MAE & substitute accuracy & avg L2 & std dev L2 & min L2 & max L2 \\ \hline
1 &  6.08 & 0.07 & 6.08 &  0.07 & 0.00 & 0.00 & 0.00 & 0.00 \\ \hline
2 & 6.99 & 0.06 & 7.5 & 20.54 & 2525.54 & 77.47 & 2102.78 & 2589.41 \\ \hline
\end{tabular}%
}
\caption{Substitute network: InceptionResNetV2 architecture with Adam optimizer; Attack: FGSM}
\label{table:semi-targeted-inception-adam-fgsm}
\end{table}

The experiment corresponding to Table \ref{table:semi-targeted-inception-adam-fgsm} is not evaluated further since the substitute network did not manage to learn, i.e. the accuracy was under 10\%. 

From the results in Tables \ref{table:semi-targeted-resnet50-sgd-fgsm},
\ref{table:semi-targeted-resnet50-adam-fgsm}, and 
\ref{table:semi-targeted-inception-sgd-fgsm} one can observe that although the substitute neural network achieves a decent accuracy (around 60\%) and get attacked successfully (accuracy reduced to 30\%), the adversarial samples do not transfer significantly. That means the substitute neural network did not manage to learn the same boundaries as the targeted neural network. 

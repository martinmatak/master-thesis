To evaluate effectiveness of the attacks, I trained a classifier for age estimation. 
First I describe the dataset I used to train the classifier and then I present results of training. 

For training data, I created a dataset based on two datasets: the APPA-REAL dataset \cite{agustsson2017appareal}  and the UTK Face dataset \footnote{https://susanqq.github.io/UTKFace/}.

The APPA-REAL dataset contains 7,591 images with associated age labels. The dataset is split into 4113 training, 1500 valid, and 1978 test images. For each image in the dataset, there is also the corresponding image which contains the cropped face. The distribution of samples over age for training dataset is presented in Figure \ref{fig:appa-train-stats}.

The UTK Face dataset consists of 23252 images with associated age labels. I preprocessed every image to extract the face\footnote{every face is cropped with 40\% margin} from it. For face detection, I used the Dlib \cite{dlib09} library. The distribution of samples over age is presented in Figure \ref{fig:utk-stats}.

I constructed my training dataset as union of all images from the UTK Face dataset and training images from the APPA-REAL dataset. For my validation dataset and my test dataset I used validation images and test images from the APPA-REAL validation and test dataset, respectively. 

\begin{figure}[h]
\includegraphics[width=13cm]{utk-stats}
\caption{Number of samples per age in the UTK Face Dataset}
\label{fig:utk-stats}
\end{figure}

\begin{figure}[h]
\includegraphics[width=13cm]{appa-train}
\caption{Number of samples per age in the APPA-REAL Training Dataset}
\label{fig:appa-train-stats}
\end{figure}

Instead of training a DNN from scratch, I used a pretrained DNN that is trained on the ImageNet dataset and fine-tuned it for age estimation. In other words, I downloaded already existing model of a DNN and re-trained it for my specific task, i.e. age estimation. This technique is called \textit{transfer learning} and more information about it can be found in \cite{yosinski2014transferable}.

If a person who is 65 years old gets classified as 66 years old, a classifier did actually a good job although it didn't predict the correct class. However, if a person who is 65 years old gets classified as 6 years old, that is a significantly bigger mistake than classifying it as 66 years old. Yet, when computing an accuracy, there is no difference if a predicted class is 6 or 66 if a ground truth is 65. That is the reason why in age estimation usually a mean absolute error (MAE) of a classifier is measured instead of accuracy.

When it comes to (targeted) misclassification, there is something in the age estimation domain that needs to be taken care of. If a person is classified a year or two older, it is not a huge success for a (targeted) misclassification. In the experiments that follow, targeted version of attacks is used, but a label is set as follows. If a person is under 50 years old, the target label is 90 years old. If a person is 50 years old or older, the target label is 10 years old. 

Formally, let $y$ be the ground truth label of an input sample $\pmb x$. Then function $f(y)$ is a function that outputs the target label for the corresponding sample $\pmb x$. The function $f$ is defined as

\begin{equation}
  f(y)=\left\{
  \begin{array}{@{}ll@{}}
       10, & y \geq 50 \\
   	  90, & \text{otherwise }
  \end{array}\right.
\end{equation} 

The idea behind such a setting is to maximize the mean absolute error, i.e. make the classification as wrong as possible, using the targeted version of known attacks.  This is how I reused targeted attacks in a novel setting. Initially I put targeted labels to 0 and 100 instead of 10 and 90, respectively, but I observed a worse performance, probably because they are on the edge of the considered age range.

Two different optimizers are used in the experiments for minimizing a loss function: SGD, introduced in Section \ref{subsection:gradient-descent}, and Adam \cite{DBLP:journals/corr/KingmaB14}. Three different DNN architectures are used for training: VGG16 \cite{DBLP:journals/corr/SimonyanZ14a}, ResNet-50 \cite{DBLP:journals/corr/HeZRS15}, and InceptionResNetV2\cite{DBLP:journals/corr/SzegedyIV16}. Results of training the models based on the ResNet-50 architecture and the InceptionResNetV2 architecture are presented in Table \ref{table:trained-models}. 

The VGG16 architecture didn't show nearly as good results as the other two did, i.e. it always predicted the value of the most frequent label. Hence, I do not present the results of training the VGG16 in Table \ref{table:trained-models} and I do not evaluate any adversarial attack against it. However, if the VGG16 architecture is trained on the significantly larger IMDB-WIKI dataset, it can produce good results \cite{Rothe-IJCV-2016}. 

\begin{table}[]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
Id & Architecture & Optimizer & Validation Loss & \textbf{Validation MAE} \\ \hline
1 & ResNet-50 & SGD & 3.436 & 5.151 \\ \hline
2 & ResNet-50 & Adam & 3.456 & 6.772 \\ \hline
3 & InceptionResNetV2 & SGD & 3.086 & 4.505  \\ \hline
4 & InceptionResNetV2 & Adam & 3.268 & 3.922 \\ \hline
\end{tabular}
\caption{Different models trained}
\label{table:trained-models}
\end{table}

For the evaluation of attacks, 100 random samples are taken from the APPA-REAL test dataset. Neither of the models from Table \ref{table:trained-models} has ever been trained on any of these samples before.

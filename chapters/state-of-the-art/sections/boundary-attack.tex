This approach is also used in black-box settings and it is completely different from the attacks introduced in Sections \ref{sec:transfer-based} and \ref{sec:ensemble-approach}. The boundary attack has nothing to do with either a substitute DNN or transferability of the adversarial examples. 

The attack starts with an image of a targeted class and then, step by step, it changes it to an image of some other class while staying adversarial, i.e. classified as a target class by a DNN under the attack. In every iteration of the attack, the image is changed a little bit towards a class which will be in the image in the end, at least according to a human observer. More specifically, in every iteration of the attack, a perturbation that reduces the distance of the perturbed image (adversarial sample) towards the original input (an image of a class that is presented to a human observer) is added. For specific details how this perturbation is selected, please consult the original paper \cite{brendel2018decisionbased}.

After every change, the targeted DNN is queried to check if the image is still adversarial, i.e. classified as a target label. If not, the change is reverted. In this way, the attacker doesn't need any substitute neural network. 

However, this attack comes at cost of a large number of queries to the targeted DNN. For the targeted attack, the authors needed around $10^4$ queries to get an adversarial example. The real world systems could notice such intensive querying of their APIs and detect the attack. On top of that, the attacker needs both an image of the targeted class and an image of the class that will be presented to a human observer. That could be an obstacle when the number of classes is high because it can happen that it is not easy to find an image of a particular class.

The authors compare boundary attack with white-box CW attack, introduced in Section \ref{sec:CW}, on MNIST and CIFAR-10 dataset and produce only a bit worse results, although this attack is treating a targeted DNN as a black-box.  For more information about this approach, please consult the original paper \cite{brendel2018decisionbased}.

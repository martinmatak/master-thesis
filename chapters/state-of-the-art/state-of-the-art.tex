Machine learning is a field which is evolving quickly and therefore a lot of papers have been published in the last few years. However, since focus of this master thesis is on generating adversarial examples, related work can be separated into two topics, depending if a DNN is treated as a white-box or a black-box. 

In terms of white-box attacks, in \cite{fgsm-original}, the \textit{Fast Gradient Sign Method} is presented. It computes an adversarial image for a non-targeted attack based on the direction of the gradient of a DNN. It is presented in the Section \ref{sec:FGSM}.

In \cite{DBLP:journals/corr/PapernotMJFCS15}, the \textit{Jacobian-based Saliency Map Attack} JSMA algorithm for generating adversarial examples is presented. It is based on identifying regions in an image which have higher importance for a DNN during the classification. It is presented in the Section \ref{sec:JSMA}.

In \cite{DBLP:journals/corr/CarliniW16a}, the CW attack is presented which is based on formulating the attack as an optimization problem and using a state-of-the-art optimizer to solve it.  It is presented in the Section \ref{sec:CW}.

All three attacks, FGSM, JSMA and CW are used in the experiments in this thesis.

On the black-box side of the attacks, there is \textit{transfer-based} approach 
\cite{DBLP:journals/corr/PapernotMGJCS16}. It uses a subsitute DNN which is trained on a similar dataset as the targeted DNN. This approach is described in the Section \ref{sec:transfer-based}.

In \cite{ensemble-attack}, the authors show that adversarial samples for targeted misclassification don't transfer as well as in a pure misclassification attack. Authors suggest \textit{ensemble} approach which is described in the Section \ref{sec:ensemble-approach}.

In \cite{brendel2018decisionbased}, authors implement a completely different attack and call it \textit{Boundary Attack}. The attack starts with an image of a targeted class and then, step by step, it changes it to an image of some other class while staying adversarial, i.e. classified as a target class by a DNN under the attack. The attack is described in the Section \ref{sec:boundary-attack}.

I direct the interested reader to this survey for a detailed description \cite{survey} of the different attack strategies and defenses.

\section{Fast Gradient Sign Method (FGSM)}
\label{sec:FGSM}
\input{chapters/state-of-the-art/sections/fgsm.tex}


\section{Jacobian-based Saliency Map Attack}
\label{sec:JSMA}
\input{chapters/state-of-the-art/sections/jsma.tex}

 
\section{CW}
\label{sec:CW}
\input{chapters/state-of-the-art/sections/cw.tex}


\section{Transfer based approach}
\label{sec:transfer-based}
\input{chapters/state-of-the-art/sections/transfer-based.tex}


\section{Ensemble approach} 
\label{sec:ensemble-approach}
\input{chapters/state-of-the-art/sections/ensemble-approach.tex}


\section{Boundary attack}
\label{boundary-attack}
\input{chapters/state-of-the-art/sections/boundary-attack.tex}
